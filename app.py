import streamlit as st
from dotenv import load_dotenv
import os
from PyPDF2 import PdfReader
import openai  # openai ëª¨ë“ˆì„ importí•©ë‹ˆë‹¤.
from openai_api import get_response_from_openai  # ìˆ˜ì •ëœ get_response_from_openai í•¨ìˆ˜ë¥¼ ì‚¬ìš©
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings.openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain_community.llms import OpenAI
from langchain_community.callbacks import get_openai_callback

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ë¡œë“œí•˜ê³  ì„¤ì •
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

def add_newlines_to_response(text):
    """
    ë§ˆì¹¨í‘œ ë‹¤ìŒì— ì¤„ë°”ê¿ˆ ì¶”ê°€. ë§ˆì¹¨í‘œì™€ ë‹¤ìŒ ë¬¸ì¥ ì‚¬ì´ì˜ ê³µê°„ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ". " ëŒ€ì‹  ".\n"ì„ ì‚¬ìš©
    """
    text_with_newlines = text.replace(". ", ".\n\n")
    return text_with_newlines

def main():
    st.set_page_config(page_title="PDF Q&A")
    st.header("PDF Q&A? ğŸ’¬")
    
    pdf = st.file_uploader("PDFë¥¼ ì—…ë¡œë“œ í•˜ì„¸ìš”", type="pdf")
    if pdf is not None:
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() or ""
        
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        chunks = text_splitter.split_text(text)
        
        embeddings = OpenAIEmbeddings()
        knowledge_base = FAISS.from_texts(chunks, embeddings)
        
        # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ ë° ì²˜ë¦¬
        st.write("PDF ë‚´ìš©ì— ê´€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: ì—°ì°¨íœ´ê°€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.'")
        user_question = st.text_input("ì—…ë¡œë“œ PDFê¸°ë°˜ ì§ˆë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:")
        if user_question:
            docs = knowledge_base.similarity_search(user_question)
            
            llm = OpenAI()
            chain = load_qa_chain(llm, chain_type="stuff")
            with get_openai_callback() as cb:
                # ì˜ˆì‹œ: max_tokens ê°’ì„ 512ë¡œ ì„¤ì •
                response = chain.run(input_documents=docs, question=user_question, max_tokens=512)

                print(cb)  # ì½˜ì†” ë¡œê¹…ì„ ìœ„í•œ ì½”ë“œ

            response_with_newlines = add_newlines_to_response(response)
            
            st.text_area("ë‹µë³€", value=response_with_newlines, height=300)

if __name__ == '__main__':
    main()
